{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTtCSD_MxFGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate data rate for single channel, single sample\n",
        "def cal_RATE_one_sample_one_channel(channel, tx_power, noise):\n",
        "    diag_ch = np.diag(channel)\n",
        "    inter_ch = channel - np.diag(diag_ch)\n",
        "    tot_ch = np.multiply(channel, np.expand_dims(tx_power, -1))\n",
        "    int_ch = np.multiply(inter_ch, np.expand_dims(tx_power, -1))\n",
        "    sig_ch = np.sum(tot_ch - int_ch, axis=1)\n",
        "    int_ch = np.sum(int_ch, axis=1)\n",
        "    SINR_val = np.divide(sig_ch, int_ch + noise)\n",
        "    cap_val = np.log2(1.0 + SINR_val)\n",
        "    return cap_val\n",
        "\n",
        "# Calculate spectral and energy efficiencies\n",
        "def cal_SE_EE(channel, tx_max, noise, DUE_thr, I_thr, P_c, tx_power_mat, opt=\"EE\"):\n",
        "    num_channel = 1\n",
        "    num_D2D_user = channel.shape[0] - 1\n",
        "    tot_SE = 0\n",
        "\n",
        "    cur_cap = 0\n",
        "    DUE_mask = 1\n",
        "    CUE_mask = 1\n",
        "\n",
        "    tx_power = np.vstack((tx_power_mat, 0 * np.ones((1, 1))))\n",
        "    tx_power = np.expand_dims(tx_power, 0)\n",
        "\n",
        "    cur_ch = channel\n",
        "    cur_ch_cap = cal_RATE_one_sample_one_channel(cur_ch, tx_power[:, :, 0], noise)\n",
        "    cur_cap = cur_cap + cur_ch_cap\n",
        "\n",
        "    sum_D2D_SE_temp = np.sum(cur_cap[0, :-1])\n",
        "    sum_D2D_EE_temp = np.sum(cur_cap[0, :-1] / (tx_power[0, :-1, 0] + P_c))\n",
        "\n",
        "    D2D_SE_sum = sum_D2D_SE_temp\n",
        "    D2D_EE_sum = sum_D2D_EE_temp\n",
        "\n",
        "    return D2D_SE_sum, D2D_EE_sum\n"
      ],
      "metadata": {
        "id": "2UPYZ-n82-Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_predicted_response(predicted_response):\n",
        "    \"\"\"\n",
        "    This function processes the predicted response to ensure that:\n",
        "    - If there are no values, it returns [0, 0].\n",
        "    - If there is 1 value, it appends a 0.\n",
        "    - If there are more than 2 values, it takes only the first 2.\n",
        "    - Otherwise, it keeps the values as they are.\n",
        "    \"\"\"\n",
        "    # Check if the response is empty or has no valid values\n",
        "    if not predicted_response or predicted_response.strip() == \"\":\n",
        "        return [0, 0]\n",
        "\n",
        "    # Convert the string response to an array of values\n",
        "    numbers = [int(num) for num in re.findall(r'-?\\d+', predicted_response)]\n",
        "\n",
        "    # Filter for non-negative numbers and take the first two\n",
        "    non_negative_numbers = [num for num in numbers if num >= 0][:2]\n",
        "\n",
        "    # If there are less than 2 values, pad with zeros\n",
        "    while len(non_negative_numbers) < 2:\n",
        "        non_negative_numbers.append(0)\n",
        "\n",
        "    return non_negative_numbers"
      ],
      "metadata": {
        "id": "-6cPE6vE3VkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create DPO training dataset from input dataset\n",
        "def create_dpo_dataset_from_json(input_file, ee_val_info_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Load additional information for the validation dataset\n",
        "    with open(ee_val_info_file, \"r\") as f:\n",
        "        ee_val_info = json.load(f)\n",
        "\n",
        "    # Initialize list to store DPO dataset entries\n",
        "    dpo_dataset = []\n",
        "\n",
        "    # Create a dictionary for quick access based on sample_index\n",
        "    ee_val_info_dict = {record[\"sample_index\"]: record for record in ee_val_info}\n",
        "\n",
        "    for example in data:\n",
        "      efficiencies = []\n",
        "      sample_index = int(example[\"sample_index\"])\n",
        "\n",
        "      # Get the original information from the corresponding dataset\n",
        "      if sample_index in ee_val_info_dict:\n",
        "          original_info = ee_val_info_dict[sample_index]\n",
        "      else:\n",
        "          print(f\"Sample index {sample_index} not found in any dataset.\")\n",
        "          continue\n",
        "\n",
        "      # Extract necessary fields\n",
        "      channel = np.array(original_info[\"chan_mat_values\"])\n",
        "      tx_max = original_info[\"tx_max\"]\n",
        "      noise = original_info[\"noise\"]\n",
        "      DUE_thr = original_info[\"DUE_thr\"]\n",
        "      I_thr = original_info[\"I_thr\"]\n",
        "      P_c = original_info[\"P_c\"]\n",
        "      original_power = np.array(original_info[\"pw_vec_values\"]).flatten().reshape(2, 1)\n",
        "\n",
        "      # Extract responses\n",
        "      original_response_float = [float(x) for x in example['original_response'].split(',')]\n",
        "      original_response = [int(x) for x in original_response_float]\n",
        "\n",
        "      # Process predicted responses\n",
        "      predicted_power_1 = process_predicted_response(example[\"predicted_response_1\"])\n",
        "      predicted_power_2 = process_predicted_response(example[\"predicted_response_2\"])\n",
        "      predicted_power_3 = process_predicted_response(example[\"predicted_response_3\"])\n",
        "      predicted_responses = [predicted_power_1, predicted_power_2, predicted_power_3]\n",
        "\n",
        "      # Calculate energy efficiency for all responses\n",
        "      _, predicted_EE_1 = cal_SE_EE(channel, tx_max, noise, DUE_thr, I_thr, P_c, np.array(predicted_power_1).reshape(2, 1), opt=criteria)\n",
        "      _, predicted_EE_2 = cal_SE_EE(channel, tx_max, noise, DUE_thr, I_thr, P_c, np.array(predicted_power_2).reshape(2, 1), opt=criteria)\n",
        "      _, predicted_EE_3 = cal_SE_EE(channel, tx_max, noise, DUE_thr, I_thr, P_c, np.array(predicted_power_3).reshape(2, 1), opt=criteria)\n",
        "      efficiencies = [predicted_EE_1, predicted_EE_2, predicted_EE_3]\n",
        "\n",
        "      # Identify least preferred response (lowest efficiency)\n",
        "      least_preferred_idx = efficiencies.index(min(efficiencies))\n",
        "      least_preferred_response = [int(i) for i in predicted_responses[least_preferred_idx]]\n",
        "\n",
        "      # Prepare the DPO entry\n",
        "      dpo_entry = {\n",
        "          \"sample_index\": example[\"sample_index\"],\n",
        "          \"instruction\": example[\"instruction\"],\n",
        "          \"input\": example[\"input\"],\n",
        "          \"most_preferred_response\": (\",\".join(map(str, original_response)))+\".\",\n",
        "          \"least_preferred_response\": (\",\".join(map(str, least_preferred_response))+\".\"),\n",
        "      }\n",
        "\n",
        "      # Append to the dataset\n",
        "      dpo_dataset.append(dpo_entry)\n",
        "\n",
        "    # Save the DPO dataset as a JSON file\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(dpo_dataset, f, indent=4)"
      ],
      "metadata": {
        "id": "AyW0Th0y1-F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = 'generated_responses_ee_with_three_responses.json'  # Input file in JSON format\n",
        "ee_val_info_file = \"ee_val_data.json\"\n",
        "output_file = 'dpo_dataset.json'   # Desired output file\n",
        "\n",
        "criteria = \"EE\"\n",
        "\n",
        "create_dpo_dataset_from_json(input_file, ee_val_info_file, output_file)\n",
        "print(f\"DPO dataset saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv32WGyn2DUb",
        "outputId": "d9e89677-b503-42c1-f754-3b224a3fd15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DPO dataset saved to dpo_dataset.json\n"
          ]
        }
      ]
    }
  ]
}